import base64
import streamlit as st
from openai_handler import ask_llm, build_context
from chromadb_client import search_knowledge
from tts_engine import text_to_speech

st.set_page_config(page_title="Chatbot Gi·∫£i Tr√≠", layout="centered")
st.title("üé¨ Chatbot Gi·ªõi Thi·ªáu Phim")
st.write("H√£y h·ªèi v·ªÅ phim hay ho·∫∑c g·ª£i √Ω gi·∫£i tr√≠. V√≠ d·ª•: *Phim h√†nh ƒë·ªông ch√¢u √Çu*.")

# Nh·∫≠p truy v·∫•n ng∆∞·ªùi d√πng
user_input = st.text_input("B·∫°n:", "", help="Nh·∫≠p c√¢u h·ªèi v·ªÅ phim")

if user_input:
    with st.spinner("üîç ƒêang x·ª≠ l√Ω..."):
        # T√¨m ki·∫øm ki·∫øn th·ª©c n·ªÅn t·ª´ ChromaDB
        query_result = search_knowledge(user_input)

        # T·∫°o context cho m√¥ h√¨nh LLM
        context = build_context(query_result)

        # L·∫•y ph·∫£n h·ªìi vƒÉn b·∫£n t·ª´ m√¥ h√¨nh
        response = ask_llm(context, user_input)

        # T·∫°o n√∫t ph√°t gi·ªçng n√≥i
        if st.button("üîä Ph√°t gi·ªçng n√≥i"):
            # G·ªçi h√†m chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i
            audio_path = text_to_speech(response)

            # ƒê·ªçc file √¢m thanh v√† m√£ ho√° base64
            with open(audio_path, "rb") as f:
                audio_bytes = f.read()
                audio_base64 = base64.b64encode(audio_bytes).decode()

            # Ch√®n player v√†o giao di·ªán (kh√¥ng autoplay)
            st.markdown(f"""
                <audio controls>
                    <source src="data:audio/wav;base64,{audio_base64}" type="audio/wav">
                </audio>
            """, unsafe_allow_html=True)

        # Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi c·ªßa bot
        st.write(f"ü§ñ Bot tr·∫£ l·ªùi: {response}")
