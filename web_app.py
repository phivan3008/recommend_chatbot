import base64
import streamlit as st
from openai_handler import ask_llm, build_context
from chromadb_client import search_knowledge
from tts_engine import text_to_speech

st.set_page_config(page_title="Chatbot Giáº£i TrÃ­", layout="centered")
st.title("ğŸ¬ Chatbot Giá»›i Thiá»‡u Phim")
st.write("HÃ£y há»i vá» phim hay hoáº·c gá»£i Ã½ giáº£i trÃ­. VÃ­ dá»¥: *Phim hÃ nh Ä‘á»™ng chÃ¢u Ã‚u*.")

# Nháº­p truy váº¥n ngÆ°á»i dÃ¹ng
user_input = st.text_input("Báº¡n:", "", help="Nháº­p cÃ¢u há»i vá» phim")

if user_input:
    with st.spinner("ğŸ” Äang xá»­ lÃ½..."):
        # TÃ¬m kiáº¿m kiáº¿n thá»©c ná»n tá»« ChromaDB
        queryRestul = search_knowledge(user_input)
        #st.write("ğŸ’¡ Kiáº¿n thá»©c liÃªn quan:")
        #for doc in docs:
        #    st.markdown(f"- {doc[0]}")

        #Build context for LLM
        context = build_context(queryRestul)

        # Táº¡o pháº£n há»“i vÄƒn báº£n
        response = ask_llm(context, user_input)
        st.write(f"ğŸ¤– Bot tráº£ lá»i: {response}")

        # Táº¡o giá»ng nÃ³i
        audio_path = text_to_speech(response)

        # Táº¡o mÃ£ base64 tá»« file .wav
        with open(audio_path, "rb") as f:
            audio_bytes = f.read()
            audio_base64 = base64.b64encode(audio_bytes).decode()

        # Hiá»ƒn thá»‹ láº§n Ä‘áº§u (autoplay)
        st.markdown(f"""
            <audio autoplay>
                <source src="data:audio/wav;base64,{audio_base64}" type="audio/wav">
            </audio>
        """, unsafe_allow_html=True)

        # NÃºt phÃ¡t láº¡i
        if st.button("ğŸ” PhÃ¡t láº¡i"):
            st.markdown(f"""
                <audio autoplay>
                    <source src="data:audio/wav;base64,{audio_base64}" type="audio/wav">
                </audio>
            """, unsafe_allow_html=True)
